{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import Counter, OrderedDict\n",
    "import seaborn as sn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(path):\n",
    "    read_list =[]\n",
    "    filelist = os.listdir(path)\n",
    "    for filename in filelist:\n",
    "        # de_path = os.path.join(path, filename)\n",
    "        # print(de_path)\n",
    "        # if os.path.isfile(filename):\n",
    "        if filename.endswith(\".pickle\"):\n",
    "            read_list.append(filename)\n",
    "    return read_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_uncertain(path):\n",
    "    file = open(path, 'rb')\n",
    "    G_found = pickle.load(file)\n",
    "    return G_found\n",
    "\n",
    "def read_edgelist(path):\n",
    "    edgelist = np.genfromtxt(path, dtype='int64')\n",
    "    G=nx.Graph()\n",
    "    G.add_edges_from(edgelist)\n",
    "    return G\n",
    "\n",
    "def print_original_statistic(G):  # statistics of original graph\n",
    "    degree = [G.degree(n) for n in G.nodes()]\n",
    "    avg_degree = np.mean(degree)\n",
    "    max_degree = max(degree)\n",
    "    degree_var = []\n",
    "    for i in range(len(degree)):\n",
    "        var = (degree[i] - avg_degree)**2\n",
    "        degree_var.append(var)\n",
    "    d_v = sum(degree_var)/len(degree_var)\n",
    "    cluster_coef = nx.average_clustering(G)\n",
    "\n",
    "    # largest_cc = max(nx.connected_components(G), key=len)\n",
    "    # L_cc = G.subgraph(largest_cc)\n",
    "    # avg_distance = nx.average_shortest_path_length(L_cc)\n",
    "    # diameter = nx.diameter(L_cc)\n",
    "\n",
    "    print('number of nodes in original graph:', G.number_of_nodes())\n",
    "    print('number of edges in original graph:', G.number_of_edges())\n",
    "    print('average degree in original graph:', avg_degree)\n",
    "    print('max degree in original graph:', max_degree)\n",
    "    print('degree variance in original graph:', d_v)\n",
    "    print('average clustering coefficient in original graph:', cluster_coef)\n",
    "    # print('number of nodes of largest component in original graph:', L_cc.number_of_nodes())\n",
    "    # print('number of edges of largest component in original graph:', L_cc.number_of_edges())\n",
    "    # print('average distance of largest component in original graph:', avg_distance)\n",
    "    # print('diameter of largest component in original graph:', diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluation:\n",
    "    def __init__(self, G_found, N):\n",
    "        self.G_found = G_found # uncertain graph\n",
    "        self.N = N  # number of possible world\n",
    "        # self.G = G # original graph\n",
    "\n",
    "    def possible_world(self):\n",
    "        # r_bound = 0.5 *((b-a)/error_bound) * math.log(2/p_failure)\n",
    "        # print(r_bound)\n",
    "        possible_w = []\n",
    "        E_c = self.G_found['E_c']\n",
    "        p_list = self.G_found['p']\n",
    "        for n in range(self.N):\n",
    "            w = {}\n",
    "            E_w = []  # edge list for possible world\n",
    "            p_w = []\n",
    "            for i in range(len(E_c)):\n",
    "                random = np.random.rand()  \n",
    "                if random < p_list[i]:\n",
    "                    E_w.append(E_c[i])\n",
    "                    p_w.append(p_list[i])\n",
    "            V = set(list(np.array(E_w).flat))\n",
    "            w['V'] = V\n",
    "            w['E_w'] = E_w\n",
    "            w['p']  = p_w\n",
    "            possible_w.append(w)\n",
    "        return possible_w\n",
    "    \n",
    "    def number_of_edges(self):\n",
    "        S_ne = sum(self.G_found['p'])\n",
    "        return round(S_ne)\n",
    "    \n",
    "    def average_degree(self):\n",
    "        n = len(self.G_found['V'])\n",
    "        S_ad = 2/n * (sum(self.G_found['p']))\n",
    "        return S_ad\n",
    "\n",
    "    def max_degree(self):\n",
    "        max_d = []\n",
    "        possible_w = self.possible_world() # generate possible worlds\n",
    "        for w in possible_w:\n",
    "            # nodes = w['V']\n",
    "            edges = w['E_w']\n",
    "            p = w['p']\n",
    "            G = nx.Graph()\n",
    "            for i in range(len(edges)):\n",
    "                G.add_edge(edges[i][0], edges[i][1])  # create graph using networkx\n",
    "            degree = [G.degree(n) for n in G.nodes()]\n",
    "            max_d.append(max(degree))\n",
    "        md = sum(max_d)/len(max_d)  # average max degree of possible worlds\n",
    "        return round(md)\n",
    "\n",
    "    def degree_variance(self):\n",
    "        d_v = []\n",
    "        possible_w = self.possible_world() # generate possible worlds\n",
    "        for w in possible_w:\n",
    "            # nodes = w['V']\n",
    "            edges = w['E_w']\n",
    "            p = w['p']\n",
    "            d = []  # degree variance list\n",
    "            G = nx.Graph()\n",
    "            for i in range(len(edges)):\n",
    "                G.add_edge(edges[i][0], edges[i][1])  # create graph using networkx        \n",
    "            degree = [G.degree(n) for n in G.nodes()] # degree list\n",
    "            n = len(w['V'])\n",
    "            average_d = 2/n * (sum(w['p']))\n",
    "            for j in range(len(degree)):\n",
    "                var = (degree[j] - average_d) ** 2\n",
    "                d.append(var)\n",
    "            d_var = sum(d)/len(d)\n",
    "            d_v.append(d_var)\n",
    "        dv = sum(d_v)/len(d_v) # average degree variance of possible worlds\n",
    "        return dv\n",
    "\n",
    "    def degree_distribution(self, G):\n",
    "        possible_w = self.possible_world()\n",
    "        # degree_dis = []\n",
    "        dis = np.zeros(len(G))\n",
    "        for w in possible_w:\n",
    "            nodes = w['V']\n",
    "            edges = w['E_w']\n",
    "            G = nx.Graph()\n",
    "            for i in range(len(edges)):\n",
    "                G.add_edge(edges[i][0], edges[i][1])  # create graph using networkx\n",
    "            degree = [G.degree(n) for n in G.nodes()]\n",
    "            degree_counts = dict(Counter(degree))\n",
    "            sort_degree = OrderedDict(sorted(degree_counts.items()))\n",
    "            for i in range(len(nodes)):\n",
    "                if sort_degree.get(i):\n",
    "                    dis[i] = dis[i] + sort_degree.get(i) / len(degree)\n",
    "                else:\n",
    "                    pass\n",
    "        dis = dis/len(possible_w)\n",
    "        ind = np.argpartition(dis, -10)[-10:]\n",
    "        value = dis[ind]\n",
    "        return ind, value\n",
    "\n",
    "    def largest_component(self):\n",
    "        distance = []\n",
    "        diam = []\n",
    "        edge = []\n",
    "        node = []\n",
    "        possible_w = self.possible_world()\n",
    "        for w in possible_w:\n",
    "            # nodes = w['V']\n",
    "            edges = w['E_w']\n",
    "            p = w['p']\n",
    "            G = nx.Graph()\n",
    "            for i in range(len(edges)):\n",
    "                G.add_edge(edges[i][0], edges[i][1])\n",
    "            largest_cc = max(nx.connected_components(G), key=len)\n",
    "            L_cc = G.subgraph(largest_cc)\n",
    "            avg_dis =  nx.average_shortest_path_length(L_cc)\n",
    "            dia = nx.diameter(L_cc)\n",
    "            distance.append(avg_dis)\n",
    "            diam.append(dia)\n",
    "            edge.append(L_cc.number_of_edges())\n",
    "            node.append(L_cc.number_of_nodes())\n",
    "        number_of_edges = sum(edge)/len(edge)\n",
    "        number_of_nodes = sum(node)/len(node)\n",
    "        avg_dis = sum(distance)/len(distance)\n",
    "        d = sum(diam)/len(diam)\n",
    "        return round(number_of_edges), round(number_of_nodes), avg_dis, d\n",
    "    \n",
    "    def cluster_coefficient(self):\n",
    "        cc = []\n",
    "        possible_w = self.possible_world()\n",
    "        for w in possible_w:\n",
    "            # nodes = w['V']\n",
    "            edges = w['E_w']\n",
    "            p = w['p']\n",
    "            G = nx.Graph()\n",
    "            for i in range(len(edges)):\n",
    "                G.add_edge(edges[i][0], edges[i][1])  # create graph using networkx         \n",
    "            coef = nx.average_clustering(G)\n",
    "            cc.append(coef)\n",
    "        cluster_coef = sum(cc)/len(cc)\n",
    "        return cluster_coef\n",
    "\n",
    "    def print_uncertain_statistis(self):\n",
    "        print(\"========================================================\")\n",
    "        print('number of nodes in uncertain graph:', len(self.G_found['V']))\n",
    "        print('number of edges in uncertain graph:', self.number_of_edges())\n",
    "        print('average degree in uncertain graph:', self.average_degree())\n",
    "        print('max degree in uncertain graph:', self.max_degree())\n",
    "        print('degree variance in uncertain graph:', self.degree_variance())\n",
    "        print('average clustering coefficient in uncertain graph:', self.cluster_coefficient())\n",
    "        # number_of_edges, number_of_nodes, average_distance, diameter = self.largest_component()\n",
    "        # print('number of nodes of largest component in uncertain graph:', number_of_nodes)\n",
    "        # print('number of edges of largest component in uncertain graph:', number_of_edges)\n",
    "        # print('average distance of largest component in uncertain graph:', average_distance)\n",
    "        # print('diameter of largest component in uncertain graph:', diameter)\n",
    "        # print(\"========================================================\")\n",
    "\n",
    "    def plot_degree_dist(self, G):\n",
    "        ind, value = self.degree_distribution(G)\n",
    "        degree = [G.degree(n) for n in G.nodes()]\n",
    "        degree_counts = dict(Counter(degree))\n",
    "        sort_degree = OrderedDict(sorted(degree_counts.items()))\n",
    "        value_G = []\n",
    "        for i in ind:\n",
    "            if sort_degree.get(i):\n",
    "                value_G.append(sort_degree.get(i)/len(G))\n",
    "            else:\n",
    "                value_G.append(0)\n",
    "\n",
    "        x = ind\n",
    "        y1 = value\n",
    "        y2 = value_G\n",
    "        \n",
    "        sn.boxplot(x=x,y=y2,palette='vlag')\n",
    "        sn.stripplot(x=x, y=y1, size =4,color='red')\n",
    "        plt.xlabel('Degree')\n",
    "        plt.ylabel('Fraction of nodes')\n",
    "        plt.title('Degree Distribution')\n",
    "        plt.savefig('Degree distribution.png')\n",
    "        # return degree_dist, sort_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    G = read_edgelist('facebook_combined.txt')\n",
    "    print_original_statistic(G)\n",
    "    path = os.getcwd()\n",
    "    pickle_files = get_file(path)\n",
    "    for pickle in pickle_files:\n",
    "        G_found = read_uncertain(pickle)\n",
    "        eval = evaluation(G_found, 100)\n",
    "        eval.print_uncertain_statistis()\n",
    "        eval.plot_degree_dist(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
